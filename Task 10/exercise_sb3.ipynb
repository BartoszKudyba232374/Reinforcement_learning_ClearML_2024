{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbartoszkudyba\u001b[0m (\u001b[33mbartoszkudyba-breda-university-of-applied-sciences\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bartoszkudyba/BUAS/Y2/Reinforcement_learning_ClearML_2024/Task 10/wandb/run-20250106_155643-hf6jjvd4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g/runs/hf6jjvd4' target=\"_blank\">sparkling-valley-6</a></strong> to <a href='https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g' target=\"_blank\">https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g/runs/hf6jjvd4' target=\"_blank\">https://wandb.ai/bartoszkudyba-breda-university-of-applied-sciences/Pendulum_2g/runs/hf6jjvd4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/block_b2/lib/python3.8/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import gymnasium\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "config1 = dict(\n",
    "            total_timesteps=100000, \n",
    "            save_freq=10000, \n",
    "            gravity=2\n",
    "            )\n",
    "\n",
    "run1 = wandb.init(project='Pendulum_2g', config=config1, sync_tensorboard=True)\n",
    "\n",
    "env = gymnasium.make('CartPole-v1', render_mode='rgb_array')\n",
    "model = PPO('MlpPolicy', env, verbose=1, device='mps', tensorboard_log=f\"runs/{run1.id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs/hf6jjvd4/PPO_1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0710f5ab0f7a4d0aa4408c47ec0e96c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21       |\n",
      "|    ep_rew_mean     | 21       |\n",
      "| time/              |          |\n",
      "|    fps             | 266      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.4        |\n",
      "|    ep_rew_mean          | 26.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 219         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162364 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.00511    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.7         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.9        |\n",
      "|    ep_rew_mean          | 34.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009026605 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.0802      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 45.4       |\n",
      "|    ep_rew_mean          | 45.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 214        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00821863 |\n",
      "|    clip_fraction        | 0.0853     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.631     |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 51.8       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 58.7         |\n",
      "|    ep_rew_mean          | 58.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063692955 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.617       |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.6         |\n",
      "|    ep_rew_mean          | 74.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 215          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068570217 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.606       |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 49.6         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cb1 = WandbCallback(model_save_freq=config1['save_freq'], model_save_path=f'models/{config1[\"gravity\"]}g_{run1.id}')\n",
    "\n",
    "model.learn(total_timesteps=config1['total_timesteps'],progress_bar=True, callback=cb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_env = gymnasium.make('CartPole-v1', render_mode='human')\n",
    "# obs, _ = test_env.reset()\n",
    "\n",
    "# for i in range(1000):\n",
    "#     action, _ = model.predict(obs, deterministic=True)\n",
    "#     obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "#     done = terminated or truncated\n",
    "    \n",
    "#     if done:\n",
    "#         test_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pendulum_env = gymnasium.make('Pendulum-v1', render_mode='rgb_array', g=config1['gravity'])\n",
    "# model = PPO('MlpPolicy', pendulum_env, verbose=0)\n",
    "# model.learn(total_timesteps=config1['total_timesteps'], progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pendulm_env = gymnasium.make('Pendulum-v1', render_mode='human', g=2)\n",
    "# obs, _ = test_pendulm_env.reset()\n",
    "\n",
    "# for i in range(1000):\n",
    "#     action, _ = model.predict(obs)\n",
    "#     obs, reward, terminated, truncated, info = test_pendulm_env.step(action)\n",
    "#     done = terminated or truncated\n",
    "    \n",
    "#     if done:\n",
    "#         test_pendulm_env.reset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/pendulum_g2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config2 = dict(total_timesteps=100000, \n",
    "#               save_freq=10000, \n",
    "#               gravity=9.81)\n",
    "\n",
    "# run2 = wandb.init(project='Pendulum_981g', config=config2)\n",
    "\n",
    "# cb2 = WandbCallback(model_save_freq=config2['save_freq'], model_save_path=f'models/{config2['gravity']}g_{run2.id}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pendulum_env_2 = gymnasium.make('Pendulum-v1', render_mode='rgb_array', g=config2['gravity'])\n",
    "# model = PPO('MlpPolicy', pendulum_env_2, verbose=1)\n",
    "# model.learn(total_timesteps=config2['total_timesteps'], progress_bar=True, callback=cb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pendulm_env = gymnasium.make('Pendulum-v1', render_mode='human', g=9.81)\n",
    "# obs, _ = test_pendulm_env.reset()\n",
    "\n",
    "# for i in range(1000):\n",
    "#     action, _ = model.predict(obs)\n",
    "#     obs, reward, terminated, truncated, info = test_pendulm_env.step(action)\n",
    "#     done = terminated or truncated\n",
    "    \n",
    "#     if done:\n",
    "#         test_pendulm_env.reset()\n",
    "    \n",
    "# test_pendulm_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/pendulum_g981')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_b2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
